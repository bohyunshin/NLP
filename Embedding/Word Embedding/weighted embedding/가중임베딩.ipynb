{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가중 임베딩 (weighted embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "* ratsgo님의 가중 임베딩 함수\n",
    "* a simple but tough to beat baseline for sentence embeddings, Sanjeev Arora et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수정 사항\n",
    "* 인코딩 에러 문제로, 모든 with open()에서 encoding='utf-8' 옵션을 추가함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가하고 싶은 사항 (아직 추가 안함)\n",
    "* ~pred_by_batch의 output을 모델이 예측한 라벨링, 그리고 이것과 실제 라벨링의 confusion matric을 반환하도록.~ (완료)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수의 인자 설명\n",
    "* train_fname: tokenized가 완료된 문장과 라벨이 ␞로 한줄에 이어져 있는 파일의 경로. 여기에서는 네이버 평점 데이터만 해당.\n",
    "* embedding_fname: word2vec 모델 경로\n",
    "* model_fname: 모델을 저장할 경로\n",
    "* embedding_corpus_fname: word2vec을 만들 때, 사용한 전체 corpus. 한줄에 tokenized가 완료된 문장 하나가 옴. 여기서는 네이버 평점, korquad, ko_wiki 코퍼스 모두 포함.\n",
    "* embedding_method: 임베딩 방법\n",
    "* is_weighted: 가중 임베딩을 사용할건지, 그냥 단순 평균 임베딩을 사용할건지. 두 가지 결과를 비교해볼 수 있다.\n",
    "* dim: 기본은 100차원. 임베딩 벡터의 차원 수이다.\n",
    "* tokenizer_name: 어떤 tokenizer을 사용할 것인지. 여기서 기본 tokenizer는 mecab이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weighted_embedding import CBoWModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = 'processed_ratings_train.txt'\n",
    "embedding_fname = 'word2vec'\n",
    "model_fname = 'weighted_word2vec_result'\n",
    "embedding_corpus_fname = 'corpus_mecab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weighted embeddings, complete!\n",
      "load Continuous Bag of Words model\n"
     ]
    }
   ],
   "source": [
    "cbow = CBoWModel(train_fname, embedding_fname, model_fname,\n",
    "                embedding_corpus_fname, embedding_method='word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 영화 꿀잼:  1\n",
      "절대 안봄:  0\n"
     ]
    }
   ],
   "source": [
    "# 가중 임베딩 모델 input 문장에 대한 예시\n",
    "print('이 영화 꿀잼: ', cbow.predict('이 영화 꿀잼'))\n",
    "print('절대 안봄: ', cbow.predict('절대 안봄'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 테스트 데이터 부르고 모델링 결과 맞춰보기\n",
    "* 테스트 데이터 5만개 모두 쓰면 memory error가 떠서 10000개만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data and evaluate\n",
    "tokenized_sentences, test_labels = [], []\n",
    "a = 0\n",
    "with open('processed_ratings_test.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        a+=1\n",
    "        sent_split = line.strip().split(\"\\u241E\")\n",
    "        tokenized_sentences.append(sent_split[0].split(' '))\n",
    "        test_labels.append(sent_split[1])\n",
    "        \n",
    "        if a == 1000: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = cbow.predict_by_batch(tokenized_sentences, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[343, 267],\n",
       "       [149, 241]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(pred_labels, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금은 1000개만 evaluate해서 정확도가 다소 떨어지는 것으로 보인다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
