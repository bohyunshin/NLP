{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Tutorial\n",
    "* parameter\n",
    " * input: Genism word2vec requires that a format of ‘list of lists’ for training where every document is contained in a list and every list contains lists of tokens of that document.\n",
    " * size: size of embedding vector\n",
    " * window: size of sliding window\n",
    " * min_count: minimum count of words\n",
    " * workers: number of CPU threads\n",
    " * sg: skip-gram model if 1, CBOW if 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data\n",
    "with open('C:/Users/sbh0613/Desktop/NLP/dataset/ratings_train_preprocessed.txt', \"rb\") as fp:   # Unpickling\n",
    "    pos_result = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_word_vec = [i.split(' ') for i in pos_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "word2vec_model = Word2Vec(input_word_vec, size=100, window = 2, min_count=50, workers=4, iter=100, sg=1)\n",
    "word2vec_model.save('C:/Users/sbh0613/Desktop/NLP/models/word2vec_model_naver_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 학습한 word2vec 모델을 불러오고 싶을 때 아래 함수를 사용한다.\n",
    "from model.word_eval import WordEmbeddingEvaluator\n",
    "word2vec_model = WordEmbeddingEvaluator('C:/Users/sbh0613/Desktop/NLP/models/word2vec_model_naver_train', \n",
    "                                       method='word2vec', dim=100, tokenizer_name='mecab')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어벡터를 구함.\n",
    "word_vectors = word2vec_model.wv\n",
    "\n",
    "# vocabulary list을 구함.\n",
    "vocabs = word_vectors.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08710402"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쓰레기와 탁월의 단어 벡터 거리 측정\n",
    "word_vectors.similarity(w1='쓰레기',w2='탁월')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbh0613\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.20956749, -0.2714135 ,  0.17804486, -0.19278349,  0.1988165 ,\n",
       "        0.3770221 ,  0.21801364, -0.29430252, -0.31121847, -0.02800035,\n",
       "        0.09235374, -0.53424644,  0.04297697,  0.09774055, -0.10360545,\n",
       "        0.07740165,  0.44465688,  0.06954425, -0.27863848, -0.22020577,\n",
       "       -0.04044078, -0.2902481 , -0.09414066, -0.5901348 ,  0.01796804,\n",
       "        0.3092677 , -0.43369296,  0.03256857,  0.13305701, -0.5149445 ,\n",
       "        0.05252489, -0.29507443,  0.20126377,  0.06314045, -0.3320269 ,\n",
       "       -0.41539675, -0.4046563 ,  0.21109046,  0.5398052 , -0.12966631,\n",
       "       -0.38281265, -0.2195754 ,  0.18654658, -0.28097674, -0.23865293,\n",
       "       -0.09296066, -0.24013051,  0.06899489, -0.08305453,  0.47292897,\n",
       "       -0.19410735, -0.3193878 ,  0.08562084, -0.1555618 ,  0.01400516,\n",
       "        0.00658054, -0.0379991 , -0.11890393, -0.07890681, -0.25582322,\n",
       "        0.0471723 , -0.19639114,  0.08375281, -0.09541314,  0.42391104,\n",
       "        0.15843965,  0.558122  , -0.02119793, -0.25656787, -0.06741247,\n",
       "       -0.05470372, -0.34329745, -0.09297433,  0.09888981, -0.42137668,\n",
       "       -0.03999322, -0.32145578, -0.21803385, -0.29768184, -0.24553101,\n",
       "        0.3605477 ,  0.2600772 , -0.01054911, -0.3300844 ,  0.00134015,\n",
       "       -0.6440953 , -0.16652101, -0.13107389,  0.06587216,  0.05282448,\n",
       "        0.17616837, -0.05178174, -0.51078975, -0.17114043,  0.07642186,\n",
       "        0.32552516, -0.38073412, -0.15125075,  0.24983998,  0.4139429 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쓰레기 단어 벡터 출력\n",
    "word2vec_model['쓰레기']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* most_similar을 통해 유사한 벡터를 구한다.\n",
    "* measure는 cosine similarity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbh0613\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('급', 0.6085103154182434),\n",
       " ('B', 0.6067619323730469),\n",
       " ('b', 0.5114173889160156),\n",
       " ('c', 0.438546746969223),\n",
       " ('저예산', 0.3875465393066406),\n",
       " ('쓰레기', 0.37956613302230835),\n",
       " ('아류', 0.371365487575531),\n",
       " ('킬링', 0.3663446009159088),\n",
       " ('장애', 0.36605000495910645),\n",
       " ('클레멘타인', 0.3626404404640198)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사한 벡터를 구함 by Euclidean Distance\n",
    "word2vec_model.most_similar('C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아무래도 합성어에 대해서 잘 탐지를 하지 못하는 것 같다.\n",
    "* soynlp로 합성어를 학습하고, 이를 mecab user-dic 사전에 넣는 것도 하나의 솔루션이 될 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec: using pretrained data from 박병규님 model [한글]\n",
    "* https://github.com/Kyubyong/wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_model = gensim.models.Word2Vec.load('C:/Users/sbh0613/Desktop/NLP/embedding part/word2vec/ko/ko.bin')\n",
    "a = ko_model.wv.most_similar(\"강아지\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다른 word2vec model과 병합하려면 아래의 함수를 쓰면 된다고 한다.\n",
    "* 근데 한글은 encoding 오류가 뜨는데, 아직 해결하지는 못했다.\n",
    "```python\n",
    "word2vec_model.intersect_word2vec_format(fname='C:/Users/sbh0613/Desktop/NLP/embedding part/word2vec/ko/ko.bin', binary=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec: using pretrained data from 구글 model [영어]\n",
    "* https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
