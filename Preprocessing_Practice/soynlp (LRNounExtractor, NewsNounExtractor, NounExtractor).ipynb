{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비지도 학습 기반 형태소 분석\n",
    "* 본 파일은 한국어 임베딩 3.2을 공부하며 정리한 자료임을 밝힙니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "* lovit님의 soynlp tutorial을 따라하며 공부한 자료임을 밝혀둡니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## soynlp\n",
    "\n",
    "* 데이터 패턴을 스스로 학습하는 비지도 학습 접근법을 지향\n",
    "* soynlp 에서 제공하는 WordExtractor 나 NounExtractor 는 여러 개의 문서로부터 학습한 통계 정보를 이용하여 작동\n",
    "* 비지도학습 기반 접근법들은 통계적 패턴을 이용하여 단어를 추출하기 때문에 하나의 문장 혹은 문서에서 보다는 어느 정도 규모가 있는 동일한 집단의 문서 (homogeneous documents) 에서 잘 작동\n",
    "* 영화 댓글들이나 하루의 뉴스 기사처럼 같은 단어를 이용하는 집합의 문서만 모아서 Extractors 를 학습하면 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제점 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 명사 추출기의 단점은 새로운 단어, 즉 이전에 학습한 데이터에 등장하지 않은 단어는 잘 인식하지 못한다는 점이다.<br>\n",
    "아래의 예시를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "konlpy version = 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Kkma, Okt, Hannanum, Mecab\n",
    "\n",
    "kkma = Kkma()\n",
    "okt = Okt()\n",
    "hannanum = Hannanum()\n",
    "mecab = Mecab(dicpath=\"C:\\\\mecab\\\\mecab-ko-dic\")\n",
    "print('konlpy version = %s' % konlpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꼬꼬마 명사:  ['손', '손흥민', '흥', '민', '황희찬', '대한', '대한민국', '민국', '축구', '미래']\n",
      "OKT   명사:  ['손흥민', '황희', '찬', '대한민국', '축구', '미래']\n",
      "한나눔 명사:  ['손흥민', '황희찬', '대한민국', '축구', '미래']\n",
      "Mecab 명사:  ['손흥민', '황희', '찬', '대한민국', '축구', '미래']\n"
     ]
    }
   ],
   "source": [
    "sent = \"손흥민과 황희찬은 대한민국 축구의 미래입니다.\"\n",
    "print('꼬꼬마 명사: ', kkma.nouns(sent))\n",
    "print('OKT   명사: ', okt.nouns(sent))\n",
    "print('한나눔 명사: ', hannanum.nouns(sent))\n",
    "print('Mecab 명사: ', mecab.nouns(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손흥민과 황희찬은 명사임을 우리는 알고 있지만 학습 데이터에 많이 등장하지 않아 이를 명사로 제대로 인식하지 못함을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물론 Mecab의 경우에는 이를 직접 사용자 사전에 추가할 수 있지만 일일이 추가하는 것에는 한계가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 '보코하람' 같이 외국어가 들어오면 이를 분해하는 특징도 있다. '보코하람'은 단어로 알지 못하지만 '보', '코' 라는 것은 명사로 알고 있기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꼬꼬마 명사:  ['보', '보코', '코', '테러', '소말리', '전쟁']\n",
      "OKT   명사:  ['보코하람', '테러', '소말리아', '전쟁']\n",
      "한나눔 명사:  ['보코하람', '테러', '소말리아', '전쟁']\n",
      "Mecab 명사:  ['보코', '하람', '테러', '소말리아', '전쟁']\n"
     ]
    }
   ],
   "source": [
    "sent = '보코하람 테러로 소말리아에서 전쟁이 있었어요'\n",
    "print('꼬꼬마 명사: ', kkma.nouns(sent))\n",
    "print('OKT   명사: ', okt.nouns(sent))\n",
    "print('한나눔 명사: ', hannanum.nouns(sent))\n",
    "print('Mecab 명사: ', mecab.nouns(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soynlp에서는 이러한 문제점을 보완하기 위해 L-R 구조를 이용해서 명사 추출을 하는 비지도 학습 방법을 제안한다. L-R 구조를 통해 L 옆에 등장하는 R의 분포는 L이 명사인지 아닌지를 판단하는 좋은 힌트를 얻을 수 있다.<br>\n",
    "하지만 이는 일반화할 수 없는데, 왜냐하면 보은, 순은 등은 '은'으로 끝나지만 '은'을 제외한 '보', '순'이 그 자체로 의미를 가지는 명사라고 보기 힘들기 때문이다.<br>\n",
    "어쨌든, 이 방법은 주어진 문서집합에서 어절들의 구조를 학습하여 그 주어진 문서집합의 명사를 추출한다. 학습데이터가 필요하지 않은 통계 기반의 unsupervised 학습방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRNounExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] used default noun predictor; Sejong corpus predictor\n",
      "[Noun Extractor] used noun_predictor_sejong\n",
      "[Noun Extractor] All 2398 r features was loaded\n"
     ]
    }
   ],
   "source": [
    "from soynlp.noun import LRNounExtractor\n",
    "\n",
    "noun_extractor = LRNounExtractor(\n",
    "    max_left_length=10, \n",
    "    max_right_length=7,\n",
    "    predictor_fnames=None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NounExtractor.train(sents)의 sents는 len(sents)를 할 수 있는 list 형식이다.<br> DoublespaceLineCorpus 는 한 문장이 하나의 문서이며, 한 문서 내의 문장 구분을 두 칸 띄어쓰기 형식으로 저장한 텍스트 형식이다. iter_sent=True 이면 문서가 아닌 문장 단위로 yield 를 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "튜토리얼에 사용된 데이터는 2016년 10월 20일의 뉴스로, 한글로 이루어진 223,357개의 문장이다 (soynlp의 tutorial 데이터와 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223357"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "\n",
    "corpus_fname = 'C:/Users/sbh0613/Desktop/NLP/ratsgo/my Preprocessing/2016-10-20.txt'\n",
    "sentences = DoublespaceLineCorpus(corpus_fname, iter_sent=True)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추출하고 싶은 명사의 noun score threshold와 명사의 최소 빈도수 (min count)를 parameter로 설정한다.<br>\n",
    "LRNounExtractor는 점수를 반환하는데 이의 범위는 [-1,1]이다. 이 점수에 대해 noun score threshold를 적용하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] scanning was done (L,R) has (52264, 26090) tokens\n",
      "[Noun Extractor] building L-R graph was done000 / 223357 sents\n",
      "[Noun Extractor] 14589 nouns are extracted\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nouns = noun_extractor.train_extract(\n",
    "    sentences, # input은 DoublespaceLineCorpus가 끝난 애들.\n",
    "    min_noun_score=0.3,\n",
    "    min_noun_frequency=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nouns 는 dict[str] = namedtuple 형식으로 return 된다. namedtuple 인 NounScore 에는 어절의 왼쪽에 등장한 횟수, 명사 점수, R set 이 알려진 feature 인 비율이 저장되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NounScore_v1(frequency=8325, score=0.43977009340659345, known_r_ratio=0.052089295935890095)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns['뉴스']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "박근혜 is noun? True\n",
      "우병우 is noun? True\n",
      "민정수석 is noun? True\n",
      "트와이스 is noun? False\n",
      "아이오아이 is noun? True\n"
     ]
    }
   ],
   "source": [
    "words = ['박근혜', '우병우', '민정수석', '트와이스', '아이오아이']\n",
    "for word in words:\n",
    "    print('%s is noun? %r' % (word, word in nouns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기준을 바꿔가며 명사인지 판단할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_extractor.is_noun('트와이스', min_noun_score=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NounScore_v1(frequency=270, score=0.9803828505747126, known_r_ratio=1.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns['아이오아이']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NewsNounExtractor\n",
    "\n",
    "* 뉴스 데이터에서 좋은 성능을 낼 수 있도록 함.\n",
    "* init에 입력하는 arguments는 동일."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used default noun predictor; Sejong corpus based logistic predictor\n",
      "C:/Users/sbh0613/anaconda/lib/site-packages/soynlp\n",
      "local variable 'f' referenced before assignment\n",
      "local variable 'f' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "from soynlp.noun import NewsNounExtractor\n",
    "\n",
    "noun_extractor = NewsNounExtractor(\n",
    "    max_left_length=10, \n",
    "    max_right_length=7,\n",
    "    predictor_fnames=None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan vocabulary ... \n",
      "done (Lset, Rset, Eojeol) = (658116, 363342, 403882)\n",
      "predicting noun score was done                                        \n",
      "before postprocessing 237871\n",
      "_noun_scores_ 50196\n",
      "checking hardrules ... done0 / 50196+(이)), NVsubE (사기(당)+했다) ... done\n",
      "after postprocessing 36027\n",
      "extracted 2365 compounds from eojeolss ... 87000 / 87714"
     ]
    }
   ],
   "source": [
    "nouns = noun_extractor.train_extract(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "박근혜: (score=0.478, frequency=1507)\n",
      "우병우: (score=0.757, frequency=721)\n",
      "민정수석: (score=0.834, frequency=812)\n",
      "아이오아이: (score=0.547, frequency=270)\n",
      "최순실: (score=0.828, frequency=1878)\n",
      "게이트: (score=0.745, frequency=307)\n",
      "콘서트: (score=0.769, frequency=500)\n"
     ]
    }
   ],
   "source": [
    "words = ['박근혜', '우병우', '민정수석', \n",
    "         '트와이스', '아이오아이', '최순실',\n",
    "         '최순실게이트', '게이트', '콘서트']\n",
    "\n",
    "for word in words:\n",
    "    if not word in nouns:\n",
    "        continue\n",
    "    score = nouns[word]\n",
    "    print('%s: (score=%.3f, frequency=%d)' \n",
    "          % (word, score.score, score.frequency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRNounExtractor_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명사 추출을 하기 위해 lovit님이 여러 시도를 하였는데, 앞서 살펴본 extractor ver 1과 news noun extractor, 그리고 지금부터 살펴볼 extractor ver 2가 그것들이다.<br>\n",
    "v1와 news noun extractor의 단점을 보완한 것이 ver 2이기 때문에 ver 2가 가장 좋은 성능을 낸다고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ver 2에서는 ver 1에 비해서 아래의 사항들이 개선되었다.<br>\n",
    "version 2 에서는 (1) 명사 추출의 정확성을 높였으며, (2) 합성명사의 인식이 가능. 또한 (3) 명사의 빈도를 정확히 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.493\n"
     ]
    }
   ],
   "source": [
    "import soynlp\n",
    "print(soynlp.__version__)\n",
    "\n",
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "from soynlp.noun import LRNounExtractor_v2\n",
    "\n",
    "corpus_fname = 'C:/Users/sbh0613/Desktop/NLP/ratsgo/my Preprocessing/2016-10-20.txt'\n",
    "sentences = DoublespaceLineCorpus(corpus_fname, iter_sent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용법은 ver 1와 비슷하다.<br>\n",
    "train_extract 함수를 통하여 명사 점수를 계산할 수 있다.<br>\n",
    "verbose mode 일 경우에는 학습 과정의 진행 상황이 출력된다.<br>\n",
    "자세한 차이점은 lovit님의 블로그 lovit.github.io/nlp/2018/05/08/noun_extraction_ver2 을 참조하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 train, extract을 따로 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] use default predictors\n",
      "[Noun Extractor] num features: pos=3929, neg=2321, common=107\n",
      "[Noun Extractor] counting eojeols\n",
      "[EojeolCounter] n eojeol = 403896 from 223357 sents. mem=0.154 Gb                    \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. #eojeols=4434442, mem=0.896 Gb\n",
      "[Noun Extractor] batch prediction was completed for 119705 words\n",
      "[Noun Extractor] checked compounds. discovered 70639 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 109312 -> 92205\n",
      "[Noun Extractor] postprocessing ignore_features : 92205 -> 91999\n",
      "[Noun Extractor] postprocessing ignore_NJ : 91999 -> 90643\n",
      "[Noun Extractor] 90643 nouns (70639 compounds) with min frequency=1\n",
      "[Noun Extractor] flushing was done. mem=1.016 Gb                    \n",
      "[Noun Extractor] 76.63 % eojeols are covered\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# extract_compund는 합성 명사의 추출 여부!\n",
    "noun_extractor = LRNounExtractor_v2(verbose=True, extract_compound=True)\n",
    "noun_extractor.train(sentences)\n",
    "nouns = noun_extractor.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 train, extract을 train_extract로 한번에 진행할 수 있다.<br>\n",
    "이때, min_count와 minimum_noun_score는 train_extract에서, 또는 extract에서 조절할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] counting eojeols\n",
      "[EojeolCounter] n eojeol = 403896 from 223357 sents. mem=1.072 Gb                    \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. #eojeols=4434442, mem=1.387 Gb\n",
      "[Noun Extractor] batch prediction was completed for 119705 words\n",
      "[Noun Extractor] checked compounds. discovered 70639 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 109312 -> 92205\n",
      "[Noun Extractor] postprocessing ignore_features : 92205 -> 91999\n",
      "[Noun Extractor] postprocessing ignore_NJ : 91999 -> 90643\n",
      "[Noun Extractor] 90643 nouns (70639 compounds) with min frequency=1\n",
      "[Noun Extractor] flushing was done. mem=1.379 Gb                    \n",
      "[Noun Extractor] 76.63 % eojeols are covered\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nouns = noun_extractor.train_extract(sentences)\n",
    "# nouns = noun_extractor.train_extract(sents, min_count=1, minimum_noun_score=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nouns 는 {str: NounScore} 형식의 dict이다. 추출된 명사 단어에 대한 빈도수와 명사 점수가 namedtuple 인 NounScore 로 저장되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ver 1과의 차이점으로, version 1 의 명사 추출기에서는 '뉴스'라는 left-side substring 의 빈도수를 명사의 빈도수로 이용하였습니다만, version 2 에서는 어절에서 '뉴스'가 실제로 명사로 이용된 경우만 카운팅 된다. '뉴스방송'과 같은 복합명사의 빈도수는 '뉴스'에 포함되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, ver 1에서 '뉴스'의 frequency가 8325였지만 ver 2에서는 freq가 이보다 더 적어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NounScore(frequency=4336, score=0.9548872180451128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns['뉴스']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRNounExtractor_v2._compounds_components 에는 복합 명사의 components 가 저장되어 있다. _compounds_components 는 {str:tuple of str} 형식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "복합 명사의 개수는 70639개 입니다.\n"
     ]
    }
   ],
   "source": [
    "print('복합 명사의 개수는 {0}개 입니다.'.format(len(noun_extractor._compounds_components)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "noun_extractor._compounds_components는 {복합 명사: 그 복합 명사를 이루는 명사들} 의 dictionary로 구성되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('잠수함발사탄도미사일', ('잠수함', '발사', '탄도미사일')),\n",
       " ('미사일대응능력위원회', ('미사일', '대응', '능력', '위원회')),\n",
       " ('글로벌녹색성장연구소', ('글로벌', '녹색성장', '연구소')),\n",
       " ('시카고옵션거래소', ('시카고', '옵션', '거래소')),\n",
       " ('대한민국특수임무유공', ('대한민국', '특수', '임무', '유공'))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(noun_extractor._compounds_components.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "복합 명사도 nouns 에 포함되어 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NounScore(frequency=1.0, score=18)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns['잠수함발사탄도미사일']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRNounExtractor_v2.decompose_compound 는 입력된 str 가 복합 명사일 경우, 이를 단일 명사의 tuple 로 분해한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('두바이', '월드', '센터', '시카고', '옵션', '거래소')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_extractor.decompose_compound('두바이월드센터시카고옵션거래소')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "복합명사가 아닌 경우에는 길이가 1 인 tuple 로 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('잠수함발사탄도미사일일까아닐까말까',)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_extractor.decompose_compound('잠수함발사탄도미사일일까아닐까말까')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRNounExtractor_v2 는 soynlp.utils 의 LRGraph 를 이용한다. 데이터의 L-R 구조를 살펴볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 4186),\n",
       " ('1', 3511),\n",
       " ('1코리아', 2424),\n",
       " ('1스타', 352),\n",
       " ('센터', 106),\n",
       " ('제보', 99),\n",
       " ('투데이', 62),\n",
       " ('를', 54),\n",
       " ('테이', 50),\n",
       " ('랩', 40)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_extractor.lrgraph.get_r('뉴스')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topk=10 으로 설정되어 있다. topk < 0 으로 설정하면 모든 R set 이 출력된다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 4186),\n",
       " ('1', 3511),\n",
       " ('1코리아', 2424),\n",
       " ('1스타', 352),\n",
       " ('센터', 106),\n",
       " ('제보', 99),\n",
       " ('투데이', 62),\n",
       " ('를', 54),\n",
       " ('테이', 50),\n",
       " ('랩', 40),\n",
       " ('룸', 37),\n",
       " ('팀', 35),\n",
       " ('쇼', 32),\n",
       " ('데스크', 29),\n",
       " ('로', 21),\n",
       " ('가', 18),\n",
       " ('는', 17),\n",
       " ('1과', 13),\n",
       " ('테이는', 9),\n",
       " ('랩을', 9),\n",
       " ('브리핑', 9),\n",
       " ('에', 8),\n",
       " ('속보팀', 8),\n",
       " ('파이터', 8),\n",
       " ('화면', 7),\n",
       " ('테이이자', 6),\n",
       " ('에서', 6),\n",
       " ('에디터', 6),\n",
       " ('1과의', 6),\n",
       " ('통신', 5),\n",
       " ('앵커', 5),\n",
       " ('테이와', 5),\n",
       " ('타파', 5),\n",
       " ('1스타에', 5),\n",
       " ('공장', 4),\n",
       " ('와', 4),\n",
       " ('와의', 4),\n",
       " ('1에', 4),\n",
       " ('콘텐츠팀', 4),\n",
       " ('의', 4),\n",
       " ('앤이슈', 4),\n",
       " ('앤이슈에서', 4),\n",
       " ('피드', 3),\n",
       " ('현장', 3),\n",
       " ('테이가', 3),\n",
       " ('들을', 3),\n",
       " ('8', 3),\n",
       " ('다', 3),\n",
       " ('제작과정에', 3),\n",
       " ('채널', 3),\n",
       " ('퀘어에서', 3),\n",
       " ('특급에서', 3),\n",
       " ('룸에서', 2),\n",
       " ('나', 2),\n",
       " ('도', 2),\n",
       " ('제작2부', 2),\n",
       " ('1번지', 2),\n",
       " ('분석', 2),\n",
       " ('테이리츠에', 2),\n",
       " ('래빗', 2),\n",
       " ('레터', 2),\n",
       " ('레터로', 2),\n",
       " ('그래픽', 2),\n",
       " ('에는', 2),\n",
       " ('룸은', 2),\n",
       " ('테이의', 2),\n",
       " ('브리핑에', 2),\n",
       " ('테이에', 2),\n",
       " ('앤이슈에', 2),\n",
       " ('8이', 2),\n",
       " ('에서만', 2),\n",
       " ('특급', 2),\n",
       " ('테스크', 1),\n",
       " ('타운', 1),\n",
       " ('타운을', 1),\n",
       " ('타파는', 1),\n",
       " ('코프', 1),\n",
       " ('멘트로', 1),\n",
       " ('멘트가', 1),\n",
       " ('테이리츠', 1),\n",
       " ('레터를', 1),\n",
       " ('전문', 1),\n",
       " ('래빗의', 1),\n",
       " ('래빗이', 1),\n",
       " ('입니다', 1),\n",
       " ('1은', 1),\n",
       " ('8은', 1),\n",
       " ('만', 1),\n",
       " ('테이로는', 1),\n",
       " ('9', 1),\n",
       " ('테이법', 1),\n",
       " ('정보를', 1),\n",
       " ('통신에도', 1),\n",
       " ('인에서', 1),\n",
       " ('룸으로', 1),\n",
       " ('룸을', 1),\n",
       " ('룸에', 1),\n",
       " ('인', 1),\n",
       " ('앵커의', 1),\n",
       " ('광장', 1),\n",
       " ('해설이었습니다', 1),\n",
       " ('테이로', 1),\n",
       " ('타모델선발대회', 1),\n",
       " ('쇼가', 1),\n",
       " ('타파지난해', 1),\n",
       " ('륨', 1),\n",
       " ('활용교육', 1),\n",
       " ('활용', 1),\n",
       " ('였다', 1),\n",
       " ('라인', 1),\n",
       " ('타파의', 1),\n",
       " ('데스크에서는', 1),\n",
       " ('라는', 1),\n",
       " ('경남', 1),\n",
       " ('1에서도', 1),\n",
       " ('1이', 1),\n",
       " ('1전북코리아가', 1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_extractor.lrgraph.get_r('뉴스', topk=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L-R 구조의 L parts 도 확인할 수 있다. 이 역시 topk=10 으로 기본값이 설정되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('있', 125),\n",
       " ('없', 76),\n",
       " ('만들', 37),\n",
       " ('늘', 32),\n",
       " ('맺', 29),\n",
       " ('열', 28),\n",
       " ('들', 19),\n",
       " ('입', 16),\n",
       " ('되', 14),\n",
       " ('줄', 14)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_extractor.lrgraph.get_l('었다고')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NounExtractor\n",
    "* 통계를 기반으로 단어의 경계를 학습하는 비지도 학습\n",
    "* Accessor Variety, Branching Entropy, Cohesion Score의 통계를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "from soynlp.word import WordExtractor\n",
    "\n",
    "corpus_fname = 'C:/Users/sbh0613/Desktop/NLP/ratsgo/my Preprocessing/2016-10-20.txt'\n",
    "sentences = DoublespaceLineCorpus(corpus_fname, iter_sent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train은 substrings의 빈도수를 카운팅 하는 것이며, extract는 init에 들어가는 값을 기준으로 단어를 선택하여 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.694 Gbse memory 0.768 Gb\n",
      "all cohesion probabilities was computed. # words = 16942\n",
      "all branching entropies was computed # words = 355061\n",
      "all accessor variety was computed # words = 355061\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from soynlp.word import WordExtractor\n",
    "\n",
    "word_extractor = WordExtractor(\n",
    "    min_frequency=100,\n",
    "    min_cohesion_forward=0.05, \n",
    "    min_right_branching_entropy=0.0\n",
    ")\n",
    "\n",
    "word_extractor.train(sentences)\n",
    "words = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 9048개의 단어 후보의 단어 점수가 계산되었습니다.\n"
     ]
    }
   ],
   "source": [
    "print('총 {0}개의 단어 후보의 단어 점수가 계산되었습니다.'.format(len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words는 {word:Score} 형식의 dictionary이다. Score는 soynlp/word.py에 구현되어있는 namedtuple이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'soynlp.word._word.Scores'>\n",
      "\n",
      "Scores(cohesion_forward=0.30063636035733476, cohesion_backward=0, left_branching_entropy=3.0548011243339506, right_branching_entropy=2.766022241109869, left_accessor_variety=32, right_accessor_variety=22, leftside_frequency=270, rightside_frequency=0)\n"
     ]
    }
   ],
   "source": [
    "print('type: %s\\n' % type(words['아이오아이']))\n",
    "print(words['아이오아이'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordExtractor가 계산하는 것은 다양한 종류의 단어 가능 점수들입니다. 이를 잘 조합하여 원하는 점수를 만들 수도 있습니다. 즐겨쓰는 방법 중 하나는 cohesion_forward에 right_branching_entropy를 곱하는 것으로, (1) 주어진 글자가 유기적으로 연결되어 함께 자주 나타나고, (2) 그 단어의 우측에 다양한 조사, 어미, 혹은 다른 단어가 등장하여 단어의 우측의 branching entropy가 높다는 의미입니다. from lovit님"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 cohesion_forward와 right_branching_entropy을 곱하여 만든 word_score가 **높은** 순으로 단어와 freq, cohesion, entropy을 배열한 결과이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어   (빈도수, cohesion, branching entropy)\n",
      "\n",
      "으로     (1634, 0.953, 5.334)\n",
      "까지     (654, 0.691, 5.349)\n",
      "함께     (7946, 0.912, 5.053)\n",
      "통해     (8471, 0.578, 5.278)\n",
      "에서     (7494, 0.604, 5.187)\n",
      "된다     (2681, 0.982, 4.675)\n",
      "먼저     (1112, 0.903, 4.665)\n",
      "면서     (1944, 0.458, 5.337)\n",
      "밝혔다     (8360, 0.836, 4.651)\n",
      "했다     (7070, 0.689, 4.795)\n",
      "됐다     (2219, 0.750, 4.658)\n",
      "또한     (2180, 0.440, 5.086)\n",
      "같은     (4429, 0.568, 4.832)\n",
      "됩니다     (247, 0.967, 4.272)\n",
      "새로운     (2334, 0.578, 4.784)\n",
      "말했다     (8345, 0.706, 4.540)\n",
      "관계자는     (2942, 0.501, 4.860)\n",
      "였다     (211, 0.632, 4.556)\n",
      "때문에     (4742, 0.696, 4.436)\n",
      "과정에서     (990, 0.497, 4.738)\n",
      "겁니다     (518, 0.915, 4.106)\n",
      "위해     (8888, 0.367, 5.016)\n",
      "예정이다     (3586, 0.607, 4.476)\n",
      "따라     (3669, 0.366, 4.977)\n",
      "따르면     (3470, 0.589, 4.440)\n",
      "합니다     (739, 0.421, 4.766)\n",
      "왔다     (674, 0.604, 4.396)\n",
      "냈다     (340, 0.659, 4.298)\n",
      "설명했다     (2055, 0.612, 4.370)\n",
      "너무     (1247, 0.711, 4.209)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def word_score(score):\n",
    "    return (score.cohesion_forward * math.exp(score.right_branching_entropy))\n",
    "\n",
    "print('단어   (빈도수, cohesion, branching entropy)\\n')\n",
    "for word, score in sorted(words.items(), key=lambda x:word_score(x[1]), reverse=True)[:30]:\n",
    "    print('%s     (%d, %.3f, %.3f)' % (\n",
    "            word, \n",
    "            score.leftside_frequency, \n",
    "            score.cohesion_forward,\n",
    "            score.right_branching_entropy\n",
    "            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohesion score, Branching Entropy, Accessor Variety 에 대하여 각각의 점수만 이용하고 싶은 경우에는 다음의 함수를 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " cohesion probabilities ... (1 in 17876)\r",
      "all cohesion probabilities was computed. # words = 16942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.30063636035733476, 0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohesion_scores = word_extractor.all_cohesion_scores()\n",
    "cohesion_scores['아이오아이'] # (cohesion_forward, cohesion_backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "all branching entropies was computed # words = 355061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.0548011243339506, 2.766022241109869)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branching_entropy = word_extractor.all_branching_entropy()\n",
    "branching_entropy['아이오아이'] # (left_branching_entropy, right_branching_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "all accessor variety was computed # words = 355061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 22)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accessor_variety = word_extractor.all_accessor_variety()\n",
    "accessor_variety['아이오아이'] # (left_accessor_variety, right_accessor_variety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
